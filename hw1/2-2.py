import pandas as pd
import pyarrow.parquet as pq
import glob
import numpy as np
import json
import re
import os
import time
from datetime import datetime
import matplotlib.pyplot as plt
import warnings

# å¿½ç•¥æ‰€æœ‰è­¦å‘Š
warnings.filterwarnings("ignore")

names = ["30G", "10G"]

for name in names:
    start_time = time.time()
    # ---------- è·¯å¾„ä¸æ•°æ®åŠ è½½ ----------
    dir = name + "_data_new"

    path = os.path.join("/data/qy/homework/2", dir, "part-00000.parquet")
    # path = os.path.join("/data/qy/homework/2", dir, "*.parquet")
    files = sorted(glob.glob(path))
    df = pd.concat([pq.read_table(f).to_pandas() for f in files], ignore_index=True)
    print('#' * 50, 'Dataset: ', name, '#' * 50)
    print(f"åŸå§‹æ•°æ®é‡ï¼š{len(df):,} è¡Œ")

    # ---------- æå–å¹³å‡æ¶ˆè´¹é‡‘é¢å’Œæ¶ˆè´¹æ¬¡æ•° ----------
    def extract_purchase_features(purchase_str):
        try:
            data = json.loads(purchase_str)
            return pd.Series({
                'avg_purchase': data.get('avg_price', np.nan),
                'purchase_count': len(data.get('items', []))
            })
        except:
            return pd.Series({'avg_purchase': np.nan, 'purchase_count': 0})

    purchase_features = df['purchase_history'].apply(extract_purchase_features)
    df = pd.concat([df, purchase_features], axis=1)

    # ---------- æå–ç™»å½•æ¬¡æ•°å’Œæœ€è¿‘ç™»å½•æ—¶é—´ ----------
    def extract_login_features(login_str):
        try:
            data = json.loads(login_str)
            timestamps = pd.to_datetime(data.get('timestamps', []), errors='coerce')
            login_count = data.get('login_count', 0)
            last_login = max(timestamps) if len(timestamps) > 0 else pd.NaT
            return pd.Series({
                'login_count': login_count,
                'recent_login': last_login
            })
        except:
            return pd.Series({'login_count': 0, 'recent_login': pd.NaT})

    login_features = df['login_history'].apply(extract_login_features)
    df = pd.concat([df, login_features], axis=1)

    # ---------- æ ‡å‡†åŒ–è¯„åˆ†ï¼ˆå¯æ¢æˆæ›´å¤æ‚çš„æ¨¡å‹ï¼‰ ----------
    # è®¡ç®—æœ€è¿‘ç™»å½•è·ä»Šçš„å¤©æ•°
    today = pd.Timestamp(datetime.now().date())
    df['days_since_login'] = (today - df['recent_login']).dt.days.fillna(9999)

    # å°†æ‰€æœ‰å…³é”®å­—æ®µæ ‡å‡†åŒ–ï¼ˆå½’ä¸€åŒ–å¤„ç†ï¼‰
    def normalize(series):
        return (series - series.min()) / (series.max() - series.min())

    df['score'] = (
        normalize(df['avg_purchase'].fillna(0)) * 0.4 +
        normalize(df['purchase_count']) * 0.2 +
        normalize(df['login_count']) * 0.2 +
        normalize(-df['days_since_login']) * 0.1 +
        df['is_active'] * 0.1
    )

    # ---------- æŒ‰ç…§åˆ†æ•°æ’åºè¯†åˆ« Top é«˜ä»·å€¼ç”¨æˆ· ----------
    df['value_segment'] = pd.qcut(df['score'], q=5, labels=['E', 'D', 'C', 'B', 'A'])  # ç±»ä¼¼ RFM åˆ†å±‚
    high_value_users = df[df['value_segment'] == 'A']

    print(f"ğŸ’ é«˜ä»·å€¼ç”¨æˆ·æ•°é‡ï¼š{len(high_value_users)}")
    print(high_value_users[['id', 'user_name', 'avg_purchase', 'purchase_count', 'login_count', 'days_since_login', 'score']].head(10))

    # ---------- å¯è§†åŒ–åˆ†æ•°åˆ†å¸ƒ ----------
    plt.figure(figsize=(10, 5))
    df['score'].hist(bins=50, color='orange')
    plt.title("ç”¨æˆ·ä»·å€¼è¯„åˆ†åˆ†å¸ƒ")
    plt.xlabel("Score")
    plt.ylabel("ç”¨æˆ·æ•°é‡")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("user_value_score_distribution_" + name + ".png")

    

